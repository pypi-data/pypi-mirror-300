"""Class for parsing the tab-delimited intermediate file generated by this
software."""

import csv
import logging
import os
from datetime import datetime
from typing import Dict, List

from previsedx_esopredict_qc_utils import constants
from previsedx_esopredict_qc_utils.esopredict.analysis.results.final_record import FinalRecord
from previsedx_esopredict_qc_utils.file_utils import check_infile_status

DEFAULT_VERBOSE = True


class Parser:
    """Class for parsing the tab-delimited intermediate file generated by this
    software."""

    def __init__(self, **kwargs):
        """Constructor for Parser."""
        self.config = kwargs.get("config", None)
        self.config_file = kwargs.get("config_file", None)
        self.logfile = kwargs.get("logfile", None)
        self.outdir = kwargs.get("outdir", None)
        self.verbose = kwargs.get("verbose", DEFAULT_VERBOSE)

        self.is_parsed = False
        self.rec_ctr = 0
        self.rec_list = []

        self.error_ctr = 0
        self.error_list = []
        self.sample_id_to_record_lookup = {}

        logging.info(f"Instantiated Parser in file '{os.path.abspath(__file__)}'")

    def get_records(self, infile: str) -> List[FinalRecord]:
        """Parser the tab-delimited file and retrieve a list of records.

        Args:
            infile (str): The tab-delimited results to be parsed.
        Returns:
            List(FinalRecord): The parsed records.
        """
        if self.is_parsed:
            return self.rec_list

        logging.info(f"Will attempt to parse gene file '{infile}'")

        check_infile_status(infile)

        record_ctr = 0

        with open(infile, errors="ignore") as f:
            reader = csv.reader(f, delimiter="\t")
            line_number = 0
            record_number = 0

            for row in reader:
                line_number += 1
                logging.info(f"Processing line number '{line_number}' row '{row[:5]}'")

                if line_number < constants.INTERMEDIATE_FILE_START_RECORD_LINE_NUMBER:
                    logging.info(
                        f"Skipping line number '{line_number}' since it is less than the start record line number '{constants.INTERMEDIATE_FILE_START_RECORD_LINE_NUMBER}'"
                    )
                    continue

                record_number += 1
                logging.info(
                    f"Will attempt to parse the record number '{record_number}' at line number '{line_number}'"
                )

                actin_hpp1 = None
                if isinstance(row[constants.INTERMEDIATE_FILE_ACTIN_HPP1_INDEX], str) and row[constants.INTERMEDIATE_FILE_ACTIN_HPP1_INDEX].upper() == "ND":
                    actin_hpp1 = "ND"
                else:
                    actin_hpp1 = float(row[constants.INTERMEDIATE_FILE_ACTIN_HPP1_INDEX])

                actin_fbn1 = None
                if isinstance(row[constants.INTERMEDIATE_FILE_ACTIN_FBN1_INDEX], str) and row[constants.INTERMEDIATE_FILE_ACTIN_FBN1_INDEX].upper() == "ND":
                    actin_fbn1 = "ND"
                else:
                    actin_fbn1 = float(row[constants.INTERMEDIATE_FILE_ACTIN_FBN1_INDEX])

                actin_p16 = None
                if isinstance(row[constants.INTERMEDIATE_FILE_ACTIN_P16_INDEX], str) and row[constants.INTERMEDIATE_FILE_ACTIN_P16_INDEX].upper() == "ND":
                    actin_p16 = "ND"
                else:
                    actin_p16 = float(row[constants.INTERMEDIATE_FILE_ACTIN_P16_INDEX])

                actin_runx3 = None
                if isinstance(row[constants.INTERMEDIATE_FILE_ACTIN_RUNX3_INDEX], str) and row[constants.INTERMEDIATE_FILE_ACTIN_RUNX3_INDEX].upper() == "ND":
                    actin_runx3 = "ND"
                else:
                    actin_runx3 = float(row[constants.INTERMEDIATE_FILE_ACTIN_RUNX3_INDEX])

                normalized_prognostic_score = None
                if isinstance(row[constants.INTERMEDIATE_FILE_NORMALIZED_PROGNOSTIC_SCORE_INDEX], str) and row[constants.INTERMEDIATE_FILE_NORMALIZED_PROGNOSTIC_SCORE_INDEX].upper() == "ND":
                    normalized_prognostic_score = "ND"
                else:
                    normalized_prognostic_score = float(row[constants.INTERMEDIATE_FILE_NORMALIZED_PROGNOSTIC_SCORE_INDEX])

                predicted_risk_category = None
                if isinstance(row[constants.INTERMEDIATE_FILE_PREDICTED_RISK_CATEGORY_INDEX], str) and row[constants.INTERMEDIATE_FILE_PREDICTED_RISK_CATEGORY_INDEX].upper() == "ND":
                    predicted_risk_category = "ND"
                else:
                    predicted_risk_category = str(row[constants.INTERMEDIATE_FILE_PREDICTED_RISK_CATEGORY_INDEX])

                five_year_progress_risk_index = None
                if isinstance(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_INDEX], str) and row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_INDEX].upper() == "ND":
                    five_year_progress_risk_index = "ND"
                else:
                    five_year_progress_risk_index = float(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_INDEX])

                five_year_progression_risk_ci_low = None
                if isinstance(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_LOW_INDEX], str) and row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_LOW_INDEX].upper() == "ND":
                    five_year_progression_risk_ci_low = "ND"
                else:
                    five_year_progression_risk_ci_low = float(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_LOW_INDEX])

                five_year_progression_risk_ci_high = None
                if isinstance(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_HIGH_INDEX], str) and row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_HIGH_INDEX].upper() == "ND":
                    five_year_progression_risk_ci_high = "ND"
                else:
                    five_year_progression_risk_ci_high = float(row[constants.INTERMEDIATE_FILE_5_YR_PROGRESSION_RISK_CI_HIGH_INDEX])

                try:
                    record = FinalRecord(
                        sample_id=str(row[constants.INTERMEDIATE_FILE_SAMPLE_ID_INDEX]),
                        actin_hpp1=actin_hpp1,
                        actin_fbn1=actin_fbn1,
                        actin_p16=actin_p16,
                        actin_runx3=actin_runx3,
                        fbn1_flag=float(
                            row[constants.INTERMEDIATE_FILE_FBN1_FLAG_INDEX]
                        ),
                        fbn1_nmv=float(row[constants.INTERMEDIATE_FILE_FBN1_NMV_INDEX]),
                        hpp1_flag=float(
                            row[constants.INTERMEDIATE_FILE_HPP1_FLAG_INDEX]
                        ),
                        hpp1_nmv=float(row[constants.INTERMEDIATE_FILE_HPP1_NMV_INDEX]),
                        hpp1_fbn1_nmv=float(
                            row[constants.INTERMEDIATE_FILE_HPP1_FBN1_NMV_INDEX]
                        ),
                        trans_hpp1_fbn1_nmv=float(
                            row[constants.INTERMEDIATE_FILE_TRANS_HPP1_FBN1_NMV_INDEX]
                        ),
                        p16_flag=float(row[constants.INTERMEDIATE_FILE_P16_FLAG_INDEX]),
                        p16_nmv=float(row[constants.INTERMEDIATE_FILE_P16_NMV_INDEX]),
                        trunc_p16_nmv=float(
                            row[constants.INTERMEDIATE_FILE_TRUNC_P16_NMV_INDEX]
                        ),
                        trans_p16_nmv=float(
                            row[constants.INTERMEDIATE_FILE_TRANS_P16_NMV_INDEX]
                        ),
                        runx3_flag=float(
                            row[constants.INTERMEDIATE_FILE_RUNX3_FLAG_INDEX]
                        ),
                        runx3_nmv=float(
                            row[constants.INTERMEDIATE_FILE_RUNX3_NMV_INDEX]
                        ),
                        trans_runx3_nmv=float(
                            row[constants.INTERMEDIATE_FILE_TRANS_RUNX3_NMV_INDEX]
                        ),
                        lp=float(row[constants.INTERMEDIATE_FILE_LP_INDEX]),
                        normalized_prognostic_score=normalized_prognostic_score,
                        predicted_risk_category=predicted_risk_category,
                        five_year_progress_risk_index=five_year_progress_risk_index,
                        five_year_progression_risk_ci_low=five_year_progression_risk_ci_low,
                        five_year_progression_risk_ci_high=five_year_progression_risk_ci_high,
                        age_at_biopsy=float(
                            row[constants.INTERMEDIATE_FILE_AGE_AT_BIOPSY_INDEX]
                        ),
                    )

                    logging.info(f"Record: {record}")
                    self.rec_list.append(record)
                    self.rec_ctr += 1
                    self.sample_id_to_record_lookup[record.sample_id] = record

                except Exception as e:
                    logging.error(
                        f"Encountered some exception with record number '{record_number}' at line number '{line_number}': {e}"
                    )
                    self.error_ctr += 1
                    self.error_list.append(e)

                record_ctr += 1

            logging.info(f"Processed '{record_ctr}' records in data file '{infile}'")

        if self.error_ctr > 0:
            if self.config.get("write_intermediate_tab_delimited_file_validation_report", constants.DEFAULT_WRITE_INTERMEDIATE_TAB_DELIMITED_FILE_VALIDATION_REPORT):
                self._write_validation_report(infile)
            else:
                logging.info(f"Will not write validation report for intermediate tab-delimited file '{infile}' even though there were '{self.error_ctr}' errors")

        self.is_parsed = True
        return self.rec_list

    def _write_validation_report(self, infile: str) -> None:
        """Write the validation report file.

        Args:
            infile (str): The input QuantStudio qPCR Results file that was parsed.
        """
        logging.info(f"Will attempt to generate validation report for file '{infile}'")
        # print(f"outdir {self.outdir}")
        # print(f"infile {infile}")
        basename = os.path.basename(infile)
        # print(f"basename {basename}")
        outfile = os.path.join(self.outdir, f"{basename}.validation-report.txt")

        with open(outfile, "w") as of:
            of.write(f"## method-created: {os.path.abspath(__file__)}\n")
            of.write(
                f"## date-created: {str(datetime.today().strftime('%Y-%m-%d-%H%M%S'))}\n"
            )
            of.write(f"## created-by: {os.environ.get('USER')}\n")
            of.write(f"## infile: {infile}\n")
            of.write(f"## logfile: {self.logfile}\n")

            if self.error_ctr > 0:
                of.write(
                    f"Encountered the following '{self.error_ctr}' validation errors:\n"
                )
                for error in self.error_list:
                    of.write(f"{error}\n")

        logging.info(f"Wrote file validation report file '{outfile}'")
        if self.verbose:
            print(f"Wrote file validation report file '{outfile}'")

    def get_sample_id_to_record_lookup(self, infile: str) -> Dict[str, FinalRecord]:
        if not self.is_parsed:
            self.get_records(infile)
        return self.sample_id_to_record_lookup
