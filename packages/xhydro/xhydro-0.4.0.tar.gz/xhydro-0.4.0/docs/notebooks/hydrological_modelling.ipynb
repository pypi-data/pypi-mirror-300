{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Hydrological modelling module\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>INFO</b>\n",
    "`xhydro` provides tools to execute and calibrate hydrological models, but will not prepare the model itself. This should be done beforehand.\n",
    "</div>\n",
    "\n",
    "`xhydro` provides a collection of functions that can serve as the main entry point for hydrological modelling. The entire framework is based on the `xh.modelling.hydrological_model` function and its `model_config` dictionary, which is meant to contain all necessary information to execute the given hydrological model. For example, depending on the model, it can store meteorological datasets directly, paths to datasets (netCDF files or other), csv configuration files, parameters, and basically anything that is required to configure and execute an hydrological model.\n",
    "\n",
    "It then becomes the User's responsibility to ensure that all required information for a given model are provided in the `model_config` object, both in the data preparation stage and in the hydrological model implementation. This can be addressed by calling the `xh.modelling.get_hydrological_model_inputs` function to get a list of the required keys for a given model, as well as the documentation. Parameters for that function are:\n",
    "\n",
    "- `model_name`: As listed below.\n",
    "- `required_only`: Whether to return all possible inputs, or only the required ones.\n",
    "\n",
    "Currently available models are:\n",
    "\n",
    "- `Hydrotel`\n",
    "- Raven-emulated models: `Blended`, `GR4JCN`, `HBVEC`, `HMETS`, `HYPR`, `Mohyse`, `SACSMA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xhydro as xh\n",
    "import xhydro.modelling as xhm\n",
    "\n",
    "# This function can be called to get a list of the keys for a given model, as well as its documentation.\n",
    "inputs, docs = xhm.get_hydrological_model_inputs(\"Hydrotel\", required_only=False)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "editable": true,
    "nbsphinx": "hidden",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Workaround for determining the notebook folder within a running notebook\n",
    "# This cell is not visible when the documentation is built.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "try:\n",
    "    from _finder import _find_current_folder\n",
    "\n",
    "    notebook_folder = _find_current_folder()\n",
    "except ImportError:\n",
    "    from pathlib import Path\n",
    "\n",
    "    notebook_folder = Path().cwd()\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Hydrological models can differ from one another in terms of required inputs and available functions, but an effort will be made to homogenize them as much as possible as new models get added. Currently, all models have these 3 functions:\n",
    "- `.run()` which will execute the model, reformat the outputs to be compatible with analysis tools in `xhydro`, then return the simulated streamflows as a `xarray.Dataset`.\n",
    "  - The streamflow will be called `streamflow` and have units in `m3 s-1`.\n",
    "  - In the case of 1D data (such as hydrometric stations), that dimension in the dataset will be identified trough a `cf_role: timeseries_id` attribute.\n",
    "- `.get_inputs()` to retrieve the meteorological inputs.\n",
    "- `.get_streamflow()` to retrieve the simulated streamflow.\n",
    "\n",
    "## Acquiring meteorological data\n",
    "The acquisition of raw meteorological and elevation data using the GIS module and libraries such as `xdatasets` is covered in the [GIS notebook](gis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we'll use a very small watershed in Eastern Quebec\n",
    "import leafmap\n",
    "import numpy as np\n",
    "import xdatasets as xd\n",
    "\n",
    "import xhydro.gis as xhgis\n",
    "\n",
    "# Get the watershed delieanation\n",
    "m = leafmap.Map(center=(48.7, -64.5), zoom=8, basemap=\"USGS Hydrography\")\n",
    "lng_lat = [(-64.51410670781502, 48.766612642281046)]\n",
    "gdf = xhgis.watershed_delineation(coordinates=lng_lat, map=m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spatial meteorological data from ERA5 using xdatasets\n",
    "datasets = {\n",
    "    \"era5_reanalysis_single_levels\": {\"variables\": [\"t2m\", \"tp\"]},\n",
    "}\n",
    "space = {\n",
    "    \"clip\": \"polygon\",  # bbox, point or polygon\n",
    "    \"averaging\": False,\n",
    "    \"geometry\": gdf,  # select the 2 first polygons\n",
    "    \"unique_id\": \"HYBAS_ID\",\n",
    "}\n",
    "time = {\n",
    "    \"timestep\": \"D\",\n",
    "    \"aggregation\": {\"tp\": np.nansum, \"t2m\": [np.nanmax, np.nanmin]},\n",
    "    \"start\": \"1981-01-01\",\n",
    "    \"end\": \"1982-01-01\",\n",
    "    \"timezone\": \"America/Montreal\",\n",
    "}\n",
    "\n",
    "ds = xd.Query(datasets=datasets, space=space, time=time).data.squeeze()\n",
    "# Standardize the dataset to bring it to CF standards\n",
    "ds = ds.rename(\n",
    "    {\n",
    "        \"longitude\": \"lon\",\n",
    "        \"latitude\": \"lat\",\n",
    "        \"t2m_nanmax\": \"tasmax\",\n",
    "        \"t2m_nanmin\": \"tasmin\",\n",
    "        \"tp_nansum\": \"pr\",\n",
    "    }\n",
    ")\n",
    "ds[\"lon\"].attrs[\"axis\"] = \"X\"\n",
    "ds[\"lat\"].attrs[\"axis\"] = \"Y\"\n",
    "ds[\"HYBAS_ID\"].attrs.pop(\"cf_role\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elevation data is not yet available through xdatasets, but we can use a hack to approximate that information\n",
    "import pystac_client\n",
    "import stackstac\n",
    "import xscen as xs\n",
    "\n",
    "# Acquire the Copernicus DEM for the area covered by the watershed\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    ")\n",
    "search = catalog.search(\n",
    "    collections=[\"cop-dem-glo-90\"],\n",
    "    bbox=gdf.total_bounds,\n",
    ")\n",
    "items = list(search.get_items())\n",
    "da = stackstac.stack(items)\n",
    "\n",
    "\n",
    "def _flatten(x, dim=\"time\"):\n",
    "    if len(x[dim].values) > len(set(x[dim].values)):\n",
    "        x = x.groupby(dim).map(stackstac.mosaic)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "ds_elev = _flatten(da, dim=\"time\").squeeze().to_dataset(name=\"elevation\")\n",
    "ds_elev = ds_elev.rename({\"x\": \"lon\", \"y\": \"lat\"})\n",
    "ds_elev[\"lon\"].attrs = {\n",
    "    \"standard_name\": \"longitude\",\n",
    "    \"units\": \"degrees_east\",\n",
    "    \"axis\": \"X\",\n",
    "}\n",
    "ds_elev[\"lat\"].attrs = {\n",
    "    \"standard_name\": \"latitude\",\n",
    "    \"units\": \"degrees_north\",\n",
    "    \"axis\": \"Y\",\n",
    "}\n",
    "\n",
    "# Use xscen to reproject the DEM onto ERA5's grid\n",
    "ds_elev = xs.regrid_dataset(\n",
    "    ds_elev,\n",
    "    ds,\n",
    "    weights_location=notebook_folder / \"_data\",\n",
    "    regridder_kwargs={\"method\": \"conservative\", \"skipna\": True},\n",
    ")\n",
    "\n",
    "# Assign the elevation data to the dataset\n",
    "ds = ds.assign_coords({\"z\": ds_elev[\"elevation\"].reset_coords(drop=True)})\n",
    "ds[\"z\"].attrs = {\"standard_name\": \"surface_altitude\", \"units\": \"m\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Formatting meteorological data\n",
    "Every hydrological model has different requirements when it comes to their input data. The function `xh.modelling.format_input` can be used to reformat CF-compliant datasets for use in hydrological models. Note that this function currently only supports 'Hydrotel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xh.modelling.format_input.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "nbsphinx": "hidden",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a hidden cell. We'll create a fake Hydrotel directory for the purpose of this example.\n",
    "import xhydro.testing\n",
    "\n",
    "xhydro.testing.utils.fake_hydrotel_project(\n",
    "    notebook_folder / \"_data\" / \"example_hydrotel\", meteo=False, debit_aval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hydrotel, the function will reproject 2D grids into a single dimension 'station', ensure that temperature and precipitation data are in 'Â°C' and 'mm' respectively,\n",
    "# and that the time axis is in 'days since 1970-01-01 00:00:00', among other changes.\n",
    "\n",
    "# You can also use the 'save_as' argument to save the new file(s) in your project folder.\n",
    "ds_reformatted, config = xh.modelling.format_input(\n",
    "    ds,\n",
    "    \"Hydrotel\",\n",
    "    save_as=notebook_folder / \"_data\" / \"example_hydrotel\" / \"meteo\" / \"ERA5.nc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydrotel also requires a configuration file, which will be produced by this function.\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "The following example will use the Hydrotel model. It is on the more complex side, with most of its parameters hidden within configurations files, but `xhydro` can be used to easily update configuration files, validate the project directory and the meteorological inputs, execute the model, and reformat the outputs to be more inline with CF conventions and other functions within `xhydro`.\n",
    "\n",
    "Do note that `xhydro` does not prepare the project directory itself, which should be done beforehand. What the class does, when initiating a new instance of `xhydro.modelling.Hydrotel`, is allow control on the entries located in the three main configuration files: the project file, `simulation.csv`, and `output.csv`. The other arguments for the class, as obtained from `get_hydrological_model_inputs`, are listed above. At any time after initialising the class, `update_config()` can be called to update the three configuration files. When called, this function will overwrite the CSV files on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# The executable depends on the platform\n",
    "if os.name == \"nt\":\n",
    "    executable = \"path/to/Hydrotel.exe\"\n",
    "else:\n",
    "    executable = \"hydrotel\"\n",
    "\n",
    "# Prepare the model configuration options\n",
    "model_config = {\n",
    "    \"model_name\": \"Hydrotel\",\n",
    "    \"project_dir\": notebook_folder / \"_data\" / \"example_hydrotel\",\n",
    "    \"project_file\": \"projet.csv\",\n",
    "    \"simulation_config\": {\n",
    "        \"DATE DEBUT\": \"1981-01-01\",\n",
    "        \"DATE FIN\": \"1981-12-31\",\n",
    "        \"FICHIER STATIONS METEO\": \"meteo/ERA5.nc\",\n",
    "        \"PAS DE TEMPS\": 24,\n",
    "    },\n",
    "    \"output_config\": {\"TRONCONS\": 1, \"DEBITS_AVAL\": 1},\n",
    "    \"use_defaults\": True,\n",
    "    \"executable\": executable,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "For HYDROTEL, `DATE DEBUT (start date), DATE FIN (end date), and PAS DE TEMPS (timestep frequency)` will always need to be specified, so these need to be added to `simulation_config` if they don't already exist in `simulation.csv`. Additionally, either `FICHIER STATIONS METEO (meteorological stations file)` or `FICHIER GRILLE METEO (meteorological grid file)` need to be specified to guide the model towards the meteorological data.\n",
    "\n",
    "If using the defaults, streamflow for all river reaches will be outputted. You can modify `output.csv` to change that behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that xhm.Hydrotel(**model_config) could also be used to initiate the model.\n",
    "ht = xhm.hydrological_model(model_config)\n",
    "\n",
    "print(f\"Simulation directory, taken from the project file: '{ht.simulation_dir}'\\n\")\n",
    "print(f\"Project configuration: '{ht.project_config}'\\n\")\n",
    "print(f\"Simulation configuration: '{ht.simulation_config}'\\n\")\n",
    "print(f\"Output configuration: '{ht.output_config}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Validating the meteorological data\n",
    "A few basic checks will be automatically performed prior to executing hydrological models, but a user might want to perform more advanced health checks (e.g. unrealistic meteorological inputs). This is possible through the use of `xhydro.utils.health_checks`. Consult [the 'xscen' documentation](https://xscen.readthedocs.io/en/latest/notebooks/3_diagnostics.html#Health-checks) for the full list of possible checks.\n",
    "\n",
    "In this example, we'll make sure that there are no abnormal meteorological values or sequence of values. Since the data used for this example is fake, this will raise some flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_checks = {\n",
    "    \"raise_on\": [],  # If an entry is not here, it will warn the user instead of raising an exception.\n",
    "    \"flags\": {\n",
    "        \"pr\": {  # You can have specific flags per variable.\n",
    "            \"negative_accumulation_values\": {},\n",
    "            \"very_large_precipitation_events\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmax\": {\n",
    "            \"tasmax_below_tasmin\": {},\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "        \"tasmin\": {\n",
    "            \"temperature_extremely_low\": {},\n",
    "            \"temperature_extremely_high\": {},\n",
    "            \"outside_n_standard_deviations_of_climatology\": {\"n\": 5},\n",
    "            \"values_repeating_for_n_or_more_days\": {\"n\": 5},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclim.core.units import amount2rate\n",
    "\n",
    "# We can use get_inputs() to automatically retrieve the meteorological data. This is very useful for instances like Hydrotel, where this information is hidden within configuration files.\n",
    "ds_in = ht.get_inputs()\n",
    "ds_in[\"pr\"] = amount2rate(\n",
    "    ds_in[\"pr\"]\n",
    ")  # Hydrotel-to-xclim compatibility. Precipitation in xclim needs to be a flux.\n",
    "\n",
    "# This example will raise warnings, this is normal since we're using fake data.\n",
    "xh.utils.health_checks(ds_in, **health_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Executing the model\n",
    "In most cases, a few basic checkups will be performed prior to executing the model, when the `run()` function is called. In the case of Hydrotel, these checks will be made:\n",
    "\n",
    "- All files mentioned in the configuration exist.\n",
    "- The meteorological dataset has the dimensions, coordinates, and variables named in its configuration file (e.g. `ERA5.nc.config`, in this example).\n",
    "- The dataset has a standard calendar.\n",
    "- The frequency is uniform (i.e. all time steps are equally spaced).\n",
    "- The start and end dates are contained in the dataset.\n",
    "- The dataset is complete (i.e. no missing values).\n",
    "\n",
    "Only when those checks are satisfied will the function actually execute the model. In addition, specific to Hydrotel, the following arguments can be called:\n",
    "\n",
    "- `check_missing`: *bool*. Whether to verify for missing data or not. Since this can be very time-consuming, it is False by default.\n",
    "- `dry_run`: *bool*. Put at True to simply print the command line, without executing it.\n",
    "\n",
    "Once the model has been executed, `xhydro` will automatically reformat the NetCDF to bring it closer to CF conventions and make it compatible with other `xhydro` modules. Note that for Hydrotel, this reformatting currently only supports the DEBITS_AVAL (outgoing streamflow) output option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of this example, we'll leave 'dry_run' as True.\n",
    "print(\"Command that would be run in the terminal:\")\n",
    "ht.run(check_missing=True, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the output would look like after reformatting (which was skipped by the dry_run argument)\n",
    "ht._standardise_outputs()\n",
    "ht.get_streamflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Model calibration\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>WARNING</b>\n",
    "This part of the documentation is still a work-in-progress. Only Raven-based models are currently implemented, but this notebook still uses the Dummy model.\n",
    "</div>\n",
    "\n",
    "Model calibration consists of a loop of multiple instances where: model parameters are chosen, the model is run, the results are compared to observations. The calibration functions in `xhydro` rely on `SPOTPY` to perform the optimization process.\n",
    "\n",
    "When using the calibration module, 2 additional keywords are required for the `model_config`:\n",
    "\n",
    "- `qobs`: Contains the observed streamflow used as the calibration target.\n",
    "- `parameters`: While not necessary to provide this, it is a reserved keyword used by the optimizer.\n",
    "\n",
    "The calibration function, `xh.modelling.perform_calibration`, has these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xh.modelling.perform_calibration.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare the model_config dictionary for the Dummy model\n",
    "model_config = {\n",
    "    \"model_name\": \"Dummy\",\n",
    "    \"precip\": np.array([10, 11, 12, 13, 14, 15]),\n",
    "    \"temperature\": np.array([10, 3, -5, 1, 15, 0]),\n",
    "    \"drainage_area\": np.array([10]),\n",
    "    \"qobs\": np.array([120, 130, 140, 150, 160, 170]),  # Required for calibration\n",
    "}\n",
    "\n",
    "# This model has 3 parameters. This will be their possible range.\n",
    "bounds_low = np.array([0, 0, 0])\n",
    "bounds_high = np.array([10, 10, 10])\n",
    "\n",
    "mask = np.array([0, 0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calibration\n",
    "best_parameters, best_simulation, best_objfun = xhm.perform_calibration(\n",
    "    model_config,\n",
    "    obj_func=\"mae\",\n",
    "    bounds_low=bounds_low,\n",
    "    bounds_high=bounds_high,\n",
    "    evaluations=1000,\n",
    "    algorithm=\"DDS\",\n",
    "    mask=mask,\n",
    "    sampler_kwargs={\"trials\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first output corresponds to the best set of parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output corresponds to the timeseries for the best set of parameters\n",
    "best_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second output is the value of the objective function for the best set of parameters\n",
    "best_objfun"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
